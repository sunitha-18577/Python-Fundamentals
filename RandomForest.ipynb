{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeX8QhLfdQIdxysWDnOoh1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunitha-18577/Python-Fundamentals/blob/main/RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AZvMsDiKLm_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,precision_score ,recall_score,f1_score\n",
        "from sklearn.preprocessing import StandardScaler ,OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Attempt to read the file\n",
        "    df = pd.read_csv('/Copy of glass.xlsx', encoding='latin-1')\n",
        "except FileNotFoundError:\n",
        "    # Handle the case where the file is not found\n",
        "    print(\"Error:glass.csv not found\")\n",
        "    # exit() # Consider if exiting is the desired behavior\n",
        "except pd.errors.EmptyDataError:\n",
        "    # Handle the case where the file is empty\n",
        "    print(\"Error:glass.csv is empty\")\n",
        "    # exit() # Consider if exiting is the desired behavior\n",
        "except pd.errors.ParserError:\n",
        "    # Handle the case where the file is not a valid CSV\n",
        "    print(\"Error:glass.csv is not a valid CSV file\")\n",
        "    # exit() # Consider if exiting is the desired behavior\n",
        "\n",
        "# Check for missing values only if the dataframe was successfully loaded\n",
        "if 'df' in locals():\n",
        "    print(\"Missing values:\\n\",df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsNgrX81MTqu",
        "outputId": "08fa6fd0-c514-40f1-eea2-5684cc41ef5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error:glass.csv is not a valid CSV file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df' in locals():\n",
        "    print(\"Dataset shape:\",df.shape)\n",
        "    print(\"Dataset info:\",df.info())\n",
        "    print(\"Dataset description:\",df.describe())\n",
        "    print(\"Missing values:\\n\",df.isnull().sum())\n",
        "else:\n",
        "    print(\"Cannot display dataset information as the dataframe 'df' was not loaded.\") # Message if df is not available\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9CQKVNockCP",
        "outputId": "ae8453de-0510-45bd-a942-7d27948977e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot display dataset information as the dataframe 'df' was not loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'df' in locals():\n",
        "    x=df.drop('Type',axis=1)\n",
        "    y=df['Type']\n",
        "else:\n",
        "    print(\"Dataframe 'df' was not loaded, cannot proceed with splitting.\")\n"
      ],
      "metadata": {
        "id": "abbPCjq2qgYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffdd0298-4f6b-40fa-db30-91ec560311bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe 'df' was not loaded, cannot proceed with splitting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor=ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num',StandardScaler(),['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe']),\n",
        "        ('cat',OneHotEncoder(),['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe'])\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "35e0Usf3BbDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'x' in locals() and 'y' in locals() and x is not None and y is not None: # Added check for x and y in locals\n",
        "    X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "    print(\"Data successfully split into training and testing sets.\")\n",
        "else:\n",
        "    print(\"Cannot perform train-test split as feature and target variables were not defined.\")\n",
        "    X_train, X_test, y_train, y_test = None, None, None, None # Ensure these are None if split fails\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jtSuf7uBjqq",
        "outputId": "cd033a41-9a82-4610-a9e9-b9bf3d201a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot perform train-test split as feature and target variables were not defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if X_train is not None and X_test is not None:\n",
        "    try:\n",
        "        x_train_processed=preprocessor.fit_transform(X_train)\n",
        "        x_test_processed=preprocessor.transform(X_test)\n",
        "        print(\"Data successfully preprocessed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during data preprocessing: {e}\")\n",
        "else:\n",
        "    print(\"Cannot perform data preprocessing as training and testing sets were not created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_RpSBLIB65c",
        "outputId": "964834cb-ba65-4bd8-a460-0eff36fdce52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot perform data preprocessing as training and testing sets were not created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_processed = None # Initialize processed variables to None\n",
        "x_test_processed = None\n",
        "if X_train is not None and X_test is not None:\n",
        "    try:\n",
        "        # Ensure the columns used in the preprocessor exist in the training data\n",
        "        preprocessor_cols = [col for name, trans, cols in preprocessor.transformers_ for col in cols]\n",
        "        missing_cols = [col for col in preprocessor_cols if col not in X_train.columns]\n",
        "\n",
        "        if missing_cols:\n",
        "             print(f\"Error: Columns {missing_cols} specified in the preprocessor are not found in the training data.\")\n",
        "        else:\n",
        "            x_train_processed = preprocessor.fit_transform(X_train)\n",
        "            x_test_processed = preprocessor.transform(X_test)\n",
        "            print(\"Data successfully preprocessed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during data preprocessing: {e}\")\n",
        "else:\n",
        "    print(\"Cannot perform data preprocessing as training and testing sets were not created or are None.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S3dFlFFDzlb",
        "outputId": "c48800ae-dee0-4836-a8d2-46f3f31b2f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot perform data preprocessing as training and testing sets were not created or are None.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_predictions = None\n",
        "if x_train_processed is not None and y_train is not None and x_test_processed is not None:\n",
        "    try:\n",
        "        rf_classifier=RandomForestClassifier(n_estimators=100,random_state=42)\n",
        "        rf_classifier.fit(x_train_processed,y_train)\n",
        "        rf_predictions=rf_classifier.predict(x_test_processed)\n",
        "        print(\"Random Forest Classifier trained and predictions made.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during model training or prediction: {e}\")\n",
        "else:\n",
        "    print(\"Cannot train the model as preprocessed data or target variable is not available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgZ1waYcC3ay",
        "outputId": "81b36910-7c33-4528-b94f-e1e65adfba9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot train the model as preprocessed data or target variable is not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if rf_predictions is not None and y_test is not None: # Check if predictions were made\n",
        "    print(\"Random Forest Classifier Metrics:\")\n",
        "    print(\"Accuracy:\",accuracy_score(y_test,rf_predictions))\n",
        "    print(\"Precision:\",precision_score(y_test,rf_predictions,average='weighted'))\n",
        "    print(\"Recall:\",recall_score(y_test,rf_predictions,average='weighted'))\n",
        "    print(\"F1 Score:\",f1_score(y_test,rf_predictions,average='weighted'))\n",
        "    print('\\n') # Corrected typo 'prinr' to 'print'\n",
        "else:\n",
        "    print(\"Cannot display metrics as predictions or test target variable are not available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d8ah_tfDXQq",
        "outputId": "f3e29b60-d376-455d-db2e-b40312d05018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot display metrics as predictions or test target variable are not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if x_train_processed is not None and y_train is not None and x_test_processed is not None:\n",
        "    try:\n",
        "        bagging_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "        boosting_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "        boosting_classifier.fit(x_train_processed, y_train)\n",
        "        boosting_predictions = boosting_classifier.predict(x_test_processed)\n",
        "\n",
        "        print(\"Boosting Classifier trained and predictions made.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during model training or prediction: {e}\")\n",
        "else:\n",
        "    print(\"Cannot train boosting models as preprocessed data or target variable is not available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_nxu5ucD43n",
        "outputId": "d34ac84a-a8d9-4ea7-ae12-f07a99f151ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot train boosting models as preprocessed data or target variable is not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_predictions = None\n",
        "boosting_predictions = None\n",
        "bagging_predictions = None\n",
        "\n",
        "if x_train_processed is not None and y_train is not None and x_test_processed is not None:\n",
        "    try:\n",
        "        # Train and predict with Random Forest\n",
        "        rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        rf_classifier.fit(x_train_processed, y_train)\n",
        "        rf_predictions = rf_classifier.predict(x_test_processed)\n",
        "        print(\"Random Forest Classifier trained and predictions made.\")\n",
        "\n",
        "        # Train and predict with Boosting (Gradient Boosting)\n",
        "        boosting_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "        boosting_classifier.fit(x_train_processed, y_train)\n",
        "        boosting_predictions = boosting_classifier.predict(x_test_processed)\n",
        "        print(\"Boosting Classifier (Gradient Boosting) trained and predictions made.\")\n",
        "\n",
        "        # Train and predict with Bagging (AdaBoost)\n",
        "        bagging_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "        bagging_classifier.fit(x_train_processed, y_train)\n",
        "        bagging_predictions = bagging_classifier.predict(x_test_processed) # Make predictions with the bagging classifier\n",
        "        print(\"Bagging Classifier (AdaBoost) trained and predictions made.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during model training or prediction: {e}\")\n",
        "else:\n",
        "    print(\"Cannot train models as preprocessed data or target variable is not available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl_NrgtwFjVm",
        "outputId": "ab6f2c65-aa71-41cb-8781-25f952d70318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot train models as preprocessed data or target variable is not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if bagging_predictions is None:\n",
        "    print(\"ERROR: Bagging predictions were not generated. Evaluation will be skipped.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzGkaarPF0RZ",
        "outputId": "7119cc25-5036-4a10-85a8-2918dccc0e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: Bagging predictions were not generated. Evaluation will be skipped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if bagging_predictions is not None and y_test is not None:\n",
        "    print(\"Bagging Model evaluation:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, bagging_predictions))\n",
        "    print(\"Precision:\", precision_score(y_test, bagging_predictions, average='weighted'))\n",
        "    print(\"Recall:\", recall_score(y_test, bagging_predictions, average='weighted'))\n",
        "    print(\"F1 Score:\", f1_score(y_test, bagging_predictions, average='weighted'))\n",
        "    print('\\n')\n",
        "else:\n",
        "    print(\"Cannot display Bagging model metrics as predictions or test target variable are not available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51BwnJo-FNF_",
        "outputId": "f608dee9-22cf-4d00-e16f-bbf423e4da30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot display Bagging model metrics as predictions or test target variable are not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if boosting_predictions is None or y_test is None:\n",
        "    print(\"ERROR: Boosting predictions or test target variable were not generated. Boosting evaluation will be skipped.\")\n",
        "else:\n",
        "    print(\"Boosting Model evaluation\")\n",
        "    print(\"Accuracy  :\",accuracy_score(y_test,boosting_predictions))\n",
        "    print(\"Precision :\",precision_score(y_test,boosting_predictions,average='weighted'))\n",
        "    print(\"Recall    :\",recall_score(y_test,boosting_predictions,average='weighted'))\n",
        "    print(\"F1 Score  :\",f1_score(y_test,boosting_predictions,average='weighted'))\n",
        "    print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoZsy-TaFPbg",
        "outputId": "5ad1cade-9ce1-40b6-d894-3eef113e806d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: Boosting predictions or test target variable were not generated. Boosting evaluation will be skipped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEToHgJRIgr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bagging and boosting:\")\n",
        "print(\"Bagging(Bootstrap Aggregation)\")\n",
        "print(\"-Creates multiple subset of original dataset (sampling with replacements.)\")\n",
        "print(\"-Trains a model on each subset independently\")\n",
        "print(\"-Averages or combines the predictions to make the final predivtions \")\n",
        "print(\"-Aims to reduce variance \")\n",
        "print(\"Boosting\")\n",
        "print(\"-Trains model sequentially,where each model tries to correct the mistakes of its predecessor.\")\n",
        "print(\"-Weighs the data points ,giving more weight to misclassified instances.\")\n",
        "print(\"-Combines the predictions through weighted avaraging and voting\")\n",
        "print(\"-Aims to reduce bias and variance.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcF2V2RpGRd5",
        "outputId": "28eb10f1-a46d-4c33-a289-3d32516fabb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging and boosting:\n",
            "Bagging(Bootstrap Aggregation)\n",
            "-Creates multiple subset of original dataset (sampling with replacements.)\n",
            "-Trains a model on each subset independently\n",
            "-Averages or combines the predictions to make the final predivtions \n",
            "-Aims to reduce variance \n",
            "Boosting\n",
            "-Trains model sequentially,where each model tries to correct the mistakes of its predecessor.\n",
            "-Weighs the data points ,giving more weight to misclassified instances.\n",
            "-Combines the predictions through weighted avaraging and voting\n",
            "-Aims to reduce bias and variance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YeruaVe2JKSu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}